{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/18 02:57:41 WARN Utils: Your hostname, fhmgi3sbi8tfqsopje66 resolves to a loopback address: 127.0.1.1; using 10.128.0.32 instead (on interface eth0)\n",
      "23/09/18 02:57:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c82dec45-056f-4d1d-8be3-c81e4562c6b6;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.8.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.32 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.2 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.2 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.3.0/spark-sql-kafka-0-10_2.12-3.3.0.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0!spark-sql-kafka-0-10_2.12.jar (145ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.3.0/spark-token-provider-kafka-0-10_2.12-3.3.0.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0!spark-token-provider-kafka-0-10_2.12.jar (87ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.8.1/kafka-clients-2.8.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.kafka#kafka-clients;2.8.1!kafka-clients.jar (362ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.0!jsr305.jar (85ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-pool2;2.11.1!commons-pool2.jar (95ms)\n",
      "downloading https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar ...\n",
      "\t[SUCCESSFUL ] org.spark-project.spark#unused;1.0.0!unused.jar (81ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.2/hadoop-client-runtime-3.3.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.2!hadoop-client-runtime.jar (1027ms)\n",
      "downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...\n",
      "\t[SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (97ms)\n",
      "downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.8.4/snappy-java-1.1.8.4.jar ...\n",
      "\t[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.8.4!snappy-java.jar(bundle) (113ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.32/slf4j-api-1.7.32.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.32!slf4j-api.jar (83ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.2/hadoop-client-api-3.3.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.2!hadoop-client-api.jar (407ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...\n",
      "\t[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (82ms)\n",
      ":: resolution report :: resolve 10612ms :: artifacts dl 2693ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.8.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.32 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   12  |   12  |   12  |   0   ||   12  |   12  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c82dec45-056f-4d1d-8be3-c81e4562c6b6\n",
      "\tconfs: [default]\n",
      "\t12 artifacts copied, 0 already retrieved (56631kB/176ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/18 02:57:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType\n",
    " \n",
    "spark_jars_packages = \",\".join(\n",
    "    [\n",
    "        \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0\"\n",
    "    ]\n",
    ")\n",
    " \n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master(\"local\")\n",
    "    .appName('test connect to kafka')\n",
    "    .config(\"spark.jars.packages\", spark_jars_packages)\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "df = (spark.read\n",
    "      .format('kafka')\n",
    "      .option('kafka.bootstrap.servers', 'rc1b-2erh7b35n4j4v869.mdb.yandexcloud.net:9091')\n",
    "      .option('kafka.security.protocol', 'SASL_SSL')\n",
    "      .option('kafka.sasl.mechanism', 'SCRAM-SHA-512')\n",
    "      .option('kafka.sasl.jaas.config',\n",
    "              'org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"de-student\\\" password=\\\"ltcneltyn\\\";')\n",
    "      .option(\"subscribe\", \"persist_topic\")\n",
    "      .load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- subscription_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-------------------------------------------------------------+-----+--------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+---------+------+-----------------------+-------------+\n",
      "|subscription_id|name      |description                                                  |price|currency|key  |value                                                                                                                                                       |topic        |partition|offset|timestamp              |timestampType|\n",
      "+---------------+----------+-------------------------------------------------------------+-----+--------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+---------+------+-----------------------+-------------+\n",
      "|null           |null      |null                                                         |null |null    |test |test2                                                                                                                                                       |persist_topic|0        |0     |2023-04-24 10:24:00.169|0            |\n",
      "|null           |null      |null                                                         |null |null    |test2|test3                                                                                                                                                       |persist_topic|0        |1     |2023-04-24 10:25:28.665|0            |\n",
      "|1              |Free      |Free subscription                                            |0.0  |USD     |1    |{\"subscription_id\": 1, \"name\": \"Free\", \"description\": \"Free subscription\", \"price\": 0, \"currency\": \"USD\"}                                                   |persist_topic|0        |2     |2023-05-01 17:19:57.178|0            |\n",
      "|2              |Individual|$14.95/mo. Save $6/mo.                                       |14.95|USD     |2    |{\"subscription_id\": 2, \"name\": \"Individual\", \"description\": \"$14.95/mo. Save $6/mo.\", \"price\": 14.95, \"currency\": \"USD\"}                                    |persist_topic|0        |3     |2023-05-01 17:20:14.79 |0            |\n",
      "|3              |Family    |$19.95/mo. Save $8/mo. Share with up to five other people.   |19.95|USD     |3    |{\"subscription_id\": 3, \"name\": \"Family\", \"description\": \"$19.95/mo. Save $8/mo. Share with up to five other people.\", \"price\": 19.95, \"currency\": \"USD\"}    |persist_topic|0        |4     |2023-05-01 17:20:28.517|0            |\n",
      "|4              |Premium   |$29.95/mo. Save $25/mo.** Share with up to five other people.|29.95|USD     |4    |{\"subscription_id\": 4, \"name\": \"Premium\", \"description\": \"$29.95/mo. Save $25/mo.** Share with up to five other people.\", \"price\": 29.95, \"currency\": \"USD\"}|persist_topic|0        |5     |2023-05-01 17:20:49.694|0            |\n",
      "+---------------+----------+-------------------------------------------------------------+-----+--------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+---------+------+-----------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "schema = StructType([\n",
    "    StructField(\"subscription_id\", IntegerType()),\n",
    "    StructField(\"name\", StringType()),\n",
    "    StructField(\"description\", StringType()),\n",
    "    StructField(\"price\", DoubleType()),\n",
    "    StructField(\"currency\", StringType())\n",
    "])\n",
    " \n",
    "df = (df\n",
    "      .withColumn('value', f.col('value').cast(StringType()))\n",
    "      .withColumn('key', f.col('key').cast(StringType()))\n",
    "      .withColumn('event', f.from_json(f.col('value'), schema))\n",
    "      .selectExpr('event.*', '*').drop('event')\n",
    "      )\n",
    " \n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+--------------------+-----+--------+-----+--------------------+-------------+---------+------+--------------------+-------------+\n",
      "|subscription_id|      name|         description|price|currency|  key|               value|        topic|partition|offset|           timestamp|timestampType|\n",
      "+---------------+----------+--------------------+-----+--------+-----+--------------------+-------------+---------+------+--------------------+-------------+\n",
      "|           null|      null|                null| null|    null| test|               test2|persist_topic|        0|     0|2023-04-24 10:24:...|            0|\n",
      "|           null|      null|                null| null|    null|test2|               test3|persist_topic|        0|     1|2023-04-24 10:25:...|            0|\n",
      "|              1|      Free|   Free subscription|  0.0|     USD|    1|{\"subscription_id...|persist_topic|        0|     2|2023-05-01 17:19:...|            0|\n",
      "|              2|Individual|$14.95/mo. Save $...|14.95|     USD|    2|{\"subscription_id...|persist_topic|        0|     3|2023-05-01 17:20:...|            0|\n",
      "|              3|    Family|$19.95/mo. Save $...|19.95|     USD|    3|{\"subscription_id...|persist_topic|        0|     4|2023-05-01 17:20:...|            0|\n",
      "|              4|   Premium|$29.95/mo. Save $...|29.95|     USD|    4|{\"subscription_id...|persist_topic|        0|     5|2023-05-01 17:20:...|            0|\n",
      "+---------------+----------+--------------------+-----+--------+-----+--------------------+-------------+---------+------+--------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
